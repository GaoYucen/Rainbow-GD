{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "prD-SX5Y99Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0030f33c-f400-4347-8670-7435eb517ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.2.0%2Bpt20cu118-cp39-cp39-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp39-cp39-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp39-cp39-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Installing collected packages: torch-scatter, pyg-lib, torch-sparse\n",
            "Successfully installed pyg-lib-0.2.0+pt20cu118 torch-scatter-2.1.1+pt20cu118 torch-sparse-0.6.17+pt20cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.0.tar.gz (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=909897 sha256=dd6c81f98d83e81958474ec6d38b471a88befff5729fd6fc20a1752a15df6559\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/7d/6b/17150450b80b4a3656a84330e22709ccd8dc0f8f4773ba4133\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install networkx\n",
        "# !pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install pyg-lib torch-scatter torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-geometric\n",
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LbKHJCvJ9_ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db07b16-36b5-4187-b57d-6a0f5ee61c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "# dir = 'gdrive/My Drive/ecm'\n",
        "dir = 'gdrive/My Drive'\n",
        "sys.path.append(dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huo55ie699Nn"
      },
      "source": [
        "## 1. Import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FQ0tCip999Np"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, GATConv, Linear, to_hetero, FastRGCNConv, RGCNConv, SAGEConv, GINConv, global_add_pool\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.loader import NeighborSampler\n",
        "from torch_geometric.utils import remove_self_loops, degree\n",
        "import copy\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "# aa4bc631f2a8ea08a7ea9c077eacdc1d421a7856"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "SiJQ6lUNQJUq",
        "outputId": "7f620f91-f6c6-4904-c895-638bd98f343b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAgr4LDg99Nr"
      },
      "source": [
        "## 2. Function definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgYhH8mt99Nr"
      },
      "source": [
        "#### 2.1 Graph reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CVuclhRnsyRE"
      },
      "outputs": [],
      "source": [
        "def read_graph_pygeo(node_file_name, edge_file_name, n_subarea):\n",
        "    x = []\n",
        "    nodefile = open(node_file_name)\n",
        "    newnode = nodefile.readline()\n",
        "    while newnode:\n",
        "        nodeId = int(newnode.split('\\t')[0])\n",
        "        nodeWeight = list()\n",
        "        for i in range(0, n_subarea):\n",
        "            nodeWeight.append(float(newnode.split('\\t')[i+1]))\n",
        "        x.append(nodeWeight)\n",
        "        newnode = nodefile.readline()\n",
        "    nodefile.close()\n",
        "    x = torch.tensor(x).type(torch.float)\n",
        "\n",
        "    edge_index = [[],[]]\n",
        "    edge_attr = []\n",
        "    edgefile = open(edge_file_name)\n",
        "    newedge = edgefile.readline()\n",
        "    while newedge:\n",
        "        node1 = int(newedge.split('\\t')[0])\n",
        "        node2 = int(newedge.split('\\t')[1])\n",
        "        edgeWeight = float(newedge.split('\\t')[2])\n",
        "        edge_index[0].append(node1)\n",
        "        edge_index[1].append(node2)\n",
        "        edge_attr.append([edgeWeight])\n",
        "        newedge = edgefile.readline()\n",
        "    edgefile.close()\n",
        "    edge_index = torch.tensor(edge_index).type(torch.long)\n",
        "    edge_attr = torch.tensor(edge_attr)\n",
        "    \n",
        "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_graph_pygeo2(node_file_name, edge_file_name, n_subarea, suba_file_name):\n",
        "    data_heter = HeteroData()\n",
        "    data = read_graph_pygeo(node_file_name, edge_file_name, n_subarea)\n",
        "    \n",
        "    # add two new attributes of each node (degree and total weight of all the edges)\n",
        "    _out, _in = data.edge_index\n",
        "    deg = degree(_out, data.x.size(0), dtype=data.x.dtype).reshape(-1,1)\n",
        "    x = torch.cat((data.x, deg), 1)\n",
        "    x = torch.cat((x, torch.zeros(data.x.size()[0],1)), 1)\n",
        "    for i in range(len(data.x)):\n",
        "        x[i][-1] = sum(data.edge_attr[data.edge_index[0] == i])\n",
        "    # add worker nodes\n",
        "    data_heter['worker'].x = x\n",
        "    # add subarea nodes   \n",
        "    x = []\n",
        "    subafile = open(suba_file_name)\n",
        "    newnode = subafile.readline()\n",
        "    while newnode:\n",
        "        nodeId = int(newnode.split('\\t')[0])\n",
        "        nodeWeight = list([int(newnode.split('\\t')[i]) for i in range(1,4)])\n",
        "        x.append(nodeWeight)\n",
        "        newnode = subafile.readline()\n",
        "    subafile.close()\n",
        "    data_heter['task'].x = torch.tensor(x).type(torch.float)\n",
        "    \n",
        "    # add edges between workers\n",
        "    data_heter['worker','influence','worker'].edge_index = data.edge_index.type(torch.long)\n",
        "\n",
        "    data_heter['worker','influence','worker'].edge_attr = data.edge_attr\n",
        "    # add edges between subarea nodes and worker nodes\n",
        "    x = torch.argsort(-data.x[0])[:5]\n",
        "    l = list(np.array(x))\n",
        "    y = torch.stack(data.x[0][x].split(1))\n",
        "    x = torch.stack((x,0*torch.ones(x.size()[0])),0)\n",
        "    for i in range(1,len(data.x)):\n",
        "        x = torch.cat((x, torch.stack((torch.argsort(-data.x[i])[:5],i*torch.ones(torch.argsort(-data.x[i])[:5].size()[0])),0)),1)\n",
        "        y = torch.cat((y, torch.stack(data.x[i][torch.argsort(-data.x[i])[:5]].split(1))),0)\n",
        "        t = np.array(torch.argsort(-data.x[i])[:5])+100*i\n",
        "        l += list(t)\n",
        "    data_heter['task','allocated','worker'].edge_index , data_heter['task','allocated','worker'].edge_attr = x.type(torch.long),y\n",
        "    return data_heter,l"
      ],
      "metadata": {
        "id": "kWcX9EjdDlUX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j81tM8SDH9sJ"
      },
      "source": [
        "\n",
        "#### 2.2 Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SMwdWzTlH46F"
      },
      "outputs": [],
      "source": [
        "def one_time_monte_carlo_simulation_new(task, data, curr_active_node):\n",
        "    all_activated_node = curr_active_node\n",
        "    next_active_node = set()\n",
        "    mc_pairs = []\n",
        "    \n",
        "    for node in curr_active_node:\n",
        "        loader = NeighborSampler(edge_index=data.edge_index, sizes=[-1], node_idx=torch.tensor([node]), batch_size=1)\n",
        "        Neighbordata = next(iter(loader))\n",
        "        for i in range(len(Neighbordata[1][1:])):\n",
        "            nbr = int(Neighbordata[1][i+1])\n",
        "            randval = random.random()\n",
        "            if (nbr not in all_activated_node) and randval<float(data.edge_attr[Neighbordata[2].edge_index[0,i]])*data.x[node][task]:\n",
        "                next_active_node.add(nbr)\n",
        "\n",
        "    while len(curr_active_node) != 0 and len(next_active_node) != 0:\n",
        "        curr_active_node = next_active_node.copy()\n",
        "        all_activated_node = all_activated_node | curr_active_node\n",
        "        next_active_node = set()\n",
        "        for node in curr_active_node:\n",
        "            loader = NeighborSampler(edge_index=data.edge_index, sizes=[-1], node_idx=torch.tensor([node]), batch_size=1)\n",
        "            Neighbordata = next(iter(loader))\n",
        "            for i in range(len(Neighbordata[1][1:])):\n",
        "                nbr = int(Neighbordata[1][i+1])\n",
        "                randval = random.random()\n",
        "                if (nbr not in all_activated_node) and randval<float(data.edge_attr[Neighbordata[2].edge_index[0,i]])*data.x[node][task]:\n",
        "                    next_active_node.add(nbr)\n",
        "\n",
        "    return all_activated_node\n",
        "\n",
        "\n",
        "# Get monte carlo probability\n",
        "def monte_carlo_simulations_new(MC_times, data, curr_node):\n",
        "    seed_pair = {}\n",
        "    for i in curr_node:\n",
        "      t,u = i//n_users, i%n_users\n",
        "      if t not in seed_pair.keys():\n",
        "        seed_pair[t] = [u]\n",
        "      else:\n",
        "        seed_pair[t].append(u)\n",
        "    inf = 0\n",
        "    for task in seed_pair.keys():\n",
        "      curr_node = set(seed_pair[task])\n",
        "      inf_single = 0\n",
        "      for i in range(0, MC_times):\n",
        "          inf_single += len(one_time_monte_carlo_simulation_new(task, data, curr_node))\n",
        "      inf += inf_single\n",
        "    return inf/MC_times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIke1f2s99Nu"
      },
      "source": [
        "#### 2.3 Influential GAT for Social Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "72xpo6rfXCRH"
      },
      "outputs": [],
      "source": [
        "class GAT_social(nn.Module):\n",
        "    def __init__(self,  ofeat):\n",
        "        super().__init__()\n",
        "        # parameters for the GAT\n",
        "        self.conv1 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        self.conv2 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        # for the second layer\n",
        "        self.conv3 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        self.conv4 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        # parameters for the linear layer\n",
        "        self.W3 = Linear(-1, ofeat, bias = True)\n",
        "        self.W3.weight.data.normal_(0, 0.1)\n",
        "        self.W4 = Linear(-1, ofeat, bias = True)\n",
        "        self.W4.weight.data.normal_(0, 0.1)\n",
        "        self.W5 = Linear(-1, ofeat, bias = True)\n",
        "        self.W5.weight.data.normal_(0, 0.1)\n",
        "        self.W6 = Linear(-1, ofeat, bias = True)\n",
        "        self.W6.weight.data.normal_(0, 0.1)\n",
        "\n",
        "    def forward(self, data):\n",
        "      x, edge_index = data.x, data.edge_index\n",
        "      x1 = self.conv1(x, edge_index)\n",
        "      x1 = F.relu(x1)\n",
        "      edge_index_rev = torch.flip(edge_index, dims=[0])\n",
        "      x2 = self.conv2(x, edge_index_rev)\n",
        "      x2 = F.relu(x2)\n",
        "      # for the second layer\n",
        "      # x1 = self.conv3(x1, edge_index)\n",
        "      # x1 = F.relu(x1)\n",
        "      # x2 = self.conv4(x2, edge_index_rev)\n",
        "      # x2 = F.relu(x2)\n",
        "      G1 = torch.sigmoid(self.W3(x1)+self.W4(x2))\n",
        "      G2 = torch.sigmoid(self.W5(x1)+self.W6(x2))\n",
        "      # element-wise multiplication of G1 and x1, G2 and x2, then concatenate them\n",
        "      return torch.cat((torch.mul(G1, x1), torch.mul(G2, x2)), dim = 1)    \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT_social_2(nn.Module):\n",
        "    def __init__(self,  ofeat):\n",
        "        super().__init__()\n",
        "        # parameters for the GAT\n",
        "        self.conv1 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        self.conv2 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        # for the second layer\n",
        "        self.conv3 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        self.conv4 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        # parameters for the linear layer\n",
        "        self.W3 = Linear(-1, ofeat, bias = True)\n",
        "        self.W3.weight.data.normal_(0, 0.1)\n",
        "        self.W4 = Linear(-1, ofeat, bias = True)\n",
        "        self.W4.weight.data.normal_(0, 0.1)\n",
        "        self.W5 = Linear(-1, ofeat, bias = True)\n",
        "        self.W5.weight.data.normal_(0, 0.1)\n",
        "        self.W6 = Linear(-1, ofeat, bias = True)\n",
        "        self.W6.weight.data.normal_(0, 0.1)\n",
        "\n",
        "    def forward(self, data):\n",
        "      x, edge_index = data.x, data.edge_index\n",
        "      x1 = self.conv1(x, edge_index)\n",
        "      x1 = F.relu(x1)\n",
        "      edge_index_rev = torch.flip(edge_index, dims=[0])\n",
        "      x2 = self.conv2(x, edge_index_rev)\n",
        "      x2 = F.relu(x2)\n",
        "      # for the second layer\n",
        "      x1 = self.conv3(x1, edge_index)\n",
        "      x1 = F.relu(x1)\n",
        "      x2 = self.conv4(x2, edge_index_rev)\n",
        "      x2 = F.relu(x2)\n",
        "      G1 = torch.sigmoid(self.W3(x1)+self.W4(x2))\n",
        "      G2 = torch.sigmoid(self.W5(x1)+self.W6(x2))\n",
        "      # element-wise multiplication of G1 and x1, G2 and x2, then concatenate them\n",
        "      return torch.cat((torch.mul(G1, x1), torch.mul(G2, x2)), dim = 1)    \n",
        "      "
      ],
      "metadata": {
        "id": "sAfEAhvnTHfu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparation with normal GAT\n",
        "class GAT_normal(nn.Module):\n",
        "    def __init__(self,  ofeat):\n",
        "        super().__init__()\n",
        "        # parameters for the GAT\n",
        "        self.conv1 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        self.conv2 = GATConv((-1, -1), ofeat, add_self_loops=False)\n",
        "        # parameters for the linear layer\n",
        "        self.W3 = Linear(-1, ofeat, bias = True)\n",
        "        self.W3.weight.data.normal_(0, 0.1)\n",
        "       \n",
        "    def forward(self, data):\n",
        "      x, edge_index = data.x, data.edge_index\n",
        "      x1 = self.conv1(x, edge_index)\n",
        "      x1 = F.relu(x1)\n",
        "      return torch.sigmoid(self.W3(x1))\n",
        "      "
      ],
      "metadata": {
        "id": "tMBbio2Emubr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparation with GraphSAGE\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv((-1,-1), hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.W3 = Linear(-1, out_channels, bias = True)\n",
        "        self.W3.weight.data.normal_(0, 0.1)\n",
        "        \n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return torch.sigmoid(self.W3(x))"
      ],
      "metadata": {
        "id": "CCzlhwKSoWcP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GINNet(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, num_classes):\n",
        "        super(GINNet, self).__init__()\n",
        "\n",
        "        # GIN layers\n",
        "        self.conv1 = GINConv(torch.nn.Sequential(\n",
        "            torch.nn.Linear(num_features, hidden_dim),\n",
        "            torch.nn.BatchNorm1d(hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
        "            torch.nn.BatchNorm1d(hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "        ))\n",
        "        self.conv2 = GINConv(torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
        "            torch.nn.BatchNorm1d(hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
        "            torch.nn.BatchNorm1d(hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "        ))\n",
        "\n",
        "        # MLP classifier\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
        "            torch.nn.BatchNorm1d(hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GIN layer\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_add_pool(x, batch)\n",
        "\n",
        "        # MLP classifier\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "pjToW8KQqMfY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 Relational GCN and Correlation Layer for Worker-Task Graph"
      ],
      "metadata": {
        "id": "eOQ0t4GIM5dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN(nn.Module):\n",
        "    def __init__(self, out_channels):\n",
        "        super(RGCN, self).__init__()\n",
        "        self.conv = FastRGCNConv(2*out_channels, out_channels,\n",
        "                              num_relations=num_relations)\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        for i in range(len(node_types)):\n",
        "            lin = Linear(-1, 2*out_channels)\n",
        "            lin.weight.data.normal_(0, 0.1)\n",
        "            self.lins.append(lin)\n",
        "\n",
        "    def trans_dimensions(self, g):\n",
        "        data = copy.deepcopy(g)\n",
        "        for node_type, lin in zip(node_types, self.lins):\n",
        "            data[node_type].x = lin(data[node_type].x.float())\n",
        "        return data\n",
        "\n",
        "    def forward(self, data):\n",
        "        data = self.trans_dimensions(data)\n",
        "        homogeneous_data = data.to_homogeneous()\n",
        "        edge_index, edge_type = homogeneous_data.edge_index, homogeneous_data.edge_type\n",
        "        x = self.conv(homogeneous_data.x, edge_index, edge_type)\n",
        "        return x.relu()"
      ],
      "metadata": {
        "id": "reYIg3lIM470"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBtjS3Pu99Nz"
      },
      "source": [
        "##### 2.5 Deep Q Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate the features of the nodes in the same class\n",
        "class state_aggregation_layer(nn.Module):\n",
        "    def __init__(self,ifeat1, ifeat2, ifeat3):\n",
        "        super().__init__()\n",
        "        self.ifeat1 = ifeat1\n",
        "        self.ifeat2 = ifeat2\n",
        "        self.ifeat3 = ifeat3\n",
        "        # parameters for the linear layer\n",
        "        self.W11 = Linear(-1, self.ifeat1, bias = True)\n",
        "        self.W11.weight.data.normal_(0, 0.1)\n",
        "        # self.W12 = Linear(-1, self.ifeat1, bias = True)\n",
        "        # self.W13 = Linear(-1, self.ifeat1, bias = True)\n",
        "        # self.W21 = Linear(-1, self.ifeat2, bias = True)\n",
        "        # self.W22 = Linear(-1, self.ifeat2, bias = True)\n",
        "        # self.W23 = Linear(-1, self.ifeat2, bias = True)\n",
        "        # self.W31 = Linear(-1, self.ifeat3, bias = True)\n",
        "        # self.W32 = Linear(-1, self.ifeat3, bias = True)\n",
        "        # self.W33 = Linear(-1, self.ifeat3, bias = True)\n",
        "        \n",
        "    def forward(self, x_t_rc, x_v_rc, x_v_s):\n",
        "      # G1 = torch.sigmoid(self.W11(x_t_rc)+self.W12(x_v_rc)+self.W13(x_v_s))\n",
        "      # G2 = torch.sigmoid(self.W21(x_t_rc)+self.W22(x_v_rc)+self.W23(x_v_s))\n",
        "      # G3 = torch.sigmoid(self.W31(x_t_rc)+self.W32(x_v_rc)+self.W33(x_v_s))\n",
        "      # tmp = torch.cat((torch.mul(G1,x_t_rc),torch.mul(G2,x_v_rc))) \n",
        "      # return torch.cat((tmp,torch.mul(G3,x_v_s)))\n",
        "      tmp = torch.cat((x_t_rc,x_v_rc)) \n",
        "      tmp = torch.cat((tmp,x_v_s))\n",
        "      G1 = torch.sigmoid(self.W11(tmp))\n",
        "      return G1"
      ],
      "metadata": {
        "id": "0j-nFwDwU5yD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1tNPyu_599N0"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):                                               \n",
        "        super(Net, self).__init__()     \n",
        "        self.fc1 = Linear(-1, 50)                                    \n",
        "        self.fc1.weight.data.normal_(0, 0.1)\n",
        "        self.fc2 = Linear(50, 20)                                    \n",
        "        self.fc2.weight.data.normal_(0, 0.1)                                     \n",
        "        self.fc3 = Linear(20, N_ACTIONS)                                     \n",
        "        self.fc3.weight.data.normal_(0, 0.1)\n",
        "        \n",
        "    def forward(self, x):                                                  \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        # x = self.fc3(x)\n",
        "        # x = (x - x.min())/(x.max()-x.min())\n",
        "        return x\n",
        "\n",
        "class Env():\n",
        "    def __init__(self, data1, data2, k): \n",
        "        self.reset()\n",
        "        self.data1 = data1\n",
        "        self.data2 = data2\n",
        "        self.k = k\n",
        "        self.steps = 0\n",
        "    \n",
        "    def reset(self):\n",
        "        self.all_activated_node = set()\n",
        "        # self.state = np.zeros(2*work_cha+task_cha+agg_cha)\n",
        "        self.state = np.zeros(2*work_cha)\n",
        "        self.currnode = set()\n",
        "        self.steps = 0\n",
        "        return self.state\n",
        "    \n",
        "    def step(self, action, gat_net, gcn_net, agg_net):\n",
        "        reward = monte_carlo_simulations_new(MC_times,  self.data1, self.currnode)\n",
        "        self.currnode.add(action)\n",
        "        reward = monte_carlo_simulations_new(MC_times,  self.data1, self.currnode) - reward\n",
        "        self.steps += 1\n",
        "        n = gcn_net(self.data2)\n",
        "        t = gat_net(self.data1)[action%n_users]\n",
        "        self.state = self.state + agg_net(t, n[action%n_users], n[action//n_users]).cpu().detach().numpy()\n",
        "        done = (self.steps == self.k)\n",
        "        return self.state, reward, done\n",
        "\n",
        "            \n",
        "class DQN(nn.Module):\n",
        "    def __init__(self):    \n",
        "        super(DQN, self).__init__()                                                       \n",
        "        self.eval_net, self.target_net = Net(), Net()\n",
        "        # for param in self.target_net.features.parameters():\n",
        "        #   param.requires_grad = False\n",
        "        self.target_net.fc1.weight.requires_grad = False\n",
        "        self.target_net.fc2.weight.requires_grad = False\n",
        "        self.target_net.fc3.weight.requires_grad = False\n",
        "        self.gcn_net = RGCN(task_cha)\n",
        "        self.gat_net = GAT_social(work_cha)\n",
        "        self.agg_net = state_aggregation_layer(2*work_cha,task_cha,agg_cha)                          \n",
        "        self.learn_step_counter = 0                                             # for target updating\n",
        "        self.memory_counter = 0                                                 # for storing memory\n",
        "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))   \n",
        "        self.eps = EPSILON\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LR)\n",
        "        # self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def choose_action(self, x, chosen_index_set, left_index_set):                                                                     \n",
        "        if np.random.uniform() < self.eps :\n",
        "            x = torch.tensor(x, dtype=torch.float).to(device) \n",
        "            x = self.eval_net(x).cpu().detach() \n",
        "            if len(chosen_index_set):\n",
        "              x = x.index_fill(0,torch.tensor(list(chosen_index_set)),-float('inf'))                      \n",
        "            action = x.argmax().item()\n",
        "        else:                                                             \n",
        "            action = random.choice(list(left_index_set))\n",
        "        return action    \n",
        "\n",
        "    def choose_action_ran(self, x, chosen_index_set, left_index_set):                                                                     \n",
        "        x = torch.tensor(x, dtype=torch.float).to(device) \n",
        "        x = self.eval_net(x).cpu().detach() \n",
        "        if len(chosen_index_set):\n",
        "          x = x.index_fill(1,torch.tensor(list(chosen_index_set)),-float('inf'))                      \n",
        "        action = x.argmax().item()\n",
        "        return action                                                       \n",
        "\n",
        "    def store_transition(self, s, a, r, s_):                                    \n",
        "        transition = np.hstack((s, a, r, s_))              \n",
        "        index = self.memory_counter % MEMORY_CAPACITY                         \n",
        "        self.memory[index, :] = transition                                      \n",
        "        self.memory_counter += 1                                               \n",
        "\n",
        "    def learn(self):                                       \n",
        "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:                 \n",
        "            self.target_net.load_state_dict(self.eval_net.state_dict())        \n",
        "        self.learn_step_counter += 1                                         \n",
        "\n",
        "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)           \n",
        "        b_memory = self.memory[sample_index, :]                                 \n",
        "        b_s = torch.FloatTensor(b_memory[:, :N_STATES]).to(device)\n",
        "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int)).to(device)\n",
        "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2]).to(device)\n",
        "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:]).to(device)\n",
        "\n",
        "        q_eval = self.eval_net(b_s).gather(1, b_a)\n",
        "        q_next = self.target_net(b_s_).detach()\n",
        "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)\n",
        "        # pdb.set_trace()\n",
        "\n",
        "        l = self.loss(q_eval, q_target)\n",
        "        self.optimizer.zero_grad()                                     \n",
        "        l.backward()                                               \n",
        "        self.optimizer.step()   \n",
        "        # wandb.log({'Loss': l,'Q_eval_max':q_eval.max().cpu().detach().numpy(),'Q_eval_mean':q_eval.mean().cpu().detach().numpy(),'Q_targ_max':q_target.max().cpu().detach().numpy(),'Q_target_mean':q_target.mean().cpu().detach().numpy()}) \n",
        "\n",
        "        return "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxYr3F3699N5"
      },
      "source": [
        "## 3. Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IPIurISq2sUK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_subarea = 100\n",
        "n_users = 3000\n",
        "input_file_path = dir+'/New_Gowalla'\n",
        "input_index = 0\n",
        "nodefilename = input_file_path + '/input_node_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "edgefilename = input_file_path + '/input_edge_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "subafilename = input_file_path + '/subarea_pos_subarea_' + str(n_subarea) + '_node_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "\n",
        "data = read_graph_pygeo(nodefilename, edgefilename, n_subarea).to(device)\n",
        "data2,l = read_graph_pygeo2(nodefilename, edgefilename, n_subarea, subafilename)\n",
        "data2.to(device)"
      ],
      "metadata": {
        "id": "yVlTKmnHgGrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2858055b-f234-4d9b-e9ae-bdc9d9c90312"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mworker\u001b[0m={ x=[3000, 102] },\n",
              "  \u001b[1mtask\u001b[0m={ x=[100, 3] },\n",
              "  \u001b[1m(worker, influence, worker)\u001b[0m={\n",
              "    edge_index=[2, 3350],\n",
              "    edge_attr=[3350, 1]\n",
              "  },\n",
              "  \u001b[1m(task, allocated, worker)\u001b[0m={\n",
              "    edge_index=[2, 15000],\n",
              "    edge_attr=[15000, 1]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN parameters\n",
        "work_cha = 5\n",
        "task_cha = 10\n",
        "agg_cha = 10\n",
        "# gat_net = GAT_social(work_cha)\n",
        "gat_net = GAT_social_2(work_cha)\n",
        "# gat_net = GAT_normal(work_cha)\n",
        "# gat_net = GraphSAGE(1,work_cha)\n",
        "node_types, edge_types = data2.metadata()\n",
        "num_relations = len(edge_types)\n",
        "gcn_net = RGCN(task_cha)\n",
        "agg_net = state_aggregation_layer(2*work_cha,task_cha,agg_cha)"
      ],
      "metadata": {
        "id": "3KSxwCf3q5SR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DRL parameters\n",
        "BATCH_SIZE = 32                               \n",
        "LR = 0.001                                      \n",
        "EPSILON = 0.9                                   \n",
        "GAMMA = 0.9                                    \n",
        "TARGET_REPLACE_ITER = 200                    \n",
        "MEMORY_CAPACITY = 100                    \n",
        "N_ACTIONS = n_users * n_subarea\n",
        "# N_STATES = 2*work_cha+task_cha+agg_cha\n",
        "N_STATES = 2*work_cha\n",
        "MC_times = 25\n",
        "K = 100\n",
        "EPOCH = 40"
      ],
      "metadata": {
        "id": "kAIfNTxW_NaC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_sample_G, path=None):\n",
        "    print(\"n user: %d\"%n_users)\n",
        "    print(\"n seed: %d\"%K)\n",
        "    # wandb.init(config={\"nuser\":n_users,\"nseed\":K,\"Com\":\"light weight\"},project=\"ECM-final\")\n",
        "    \n",
        "    dqn = DQN()\n",
        "    if path:\n",
        "      dqn.load_state_dict(torch.load(path, map_location=device))  \n",
        "\n",
        "    for input_index in range(n_sample_G):\n",
        "        nodefilename = input_file_path + '/input_node_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "        edgefilename = input_file_path + '/input_edge_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "        subafilename = input_file_path + '/subarea_pos_subarea_' + str(n_subarea) + '_node_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "        data = read_graph_pygeo(nodefilename, edgefilename, n_subarea).to(device)\n",
        "        data2,l = read_graph_pygeo2(nodefilename, edgefilename, n_subarea, subafilename)\n",
        "        data2.to(device)                                                        \n",
        "        env = Env(data,data2,K)\n",
        "\n",
        "\n",
        "        dqn.train()\n",
        "        dqn.to(device)\n",
        "\n",
        "        max_reward_sum = 0\n",
        "\n",
        "\n",
        "        for i in range(EPOCH):                                                 \n",
        "            print('<<<<<<<<<Episode: %s' % i)\n",
        "            s = env.reset()                                  \n",
        "            episode_reward_sum = 0    \n",
        "            all_action = set(l)                                    \n",
        "\n",
        "            while True:                                                        \n",
        "                a = dqn.choose_action(s,env.currnode,all_action - env.currnode)                             \n",
        "                s_, r, done = env.step(a, dqn.gat_net, dqn.gcn_net, dqn.agg_net)                         \n",
        "                dqn.store_transition(s, a, r, s_)                 \n",
        "                episode_reward_sum += r                          \n",
        "                s = s_          \n",
        "                # wandb.log({'steps':env.steps ,  'reward':r, 'action':a})                                      \n",
        "\n",
        "                if dqn.memory_counter > MEMORY_CAPACITY:              \n",
        "                    dqn.learn()\n",
        "                    \n",
        "\n",
        "                if done:  \n",
        "                    dqn.eps = (1+dqn.eps)/2\n",
        "                    # wandb.log({'epoch': i,  'reward_sum':round(episode_reward_sum, 2)})   \n",
        "                    print('episode%s---reward_sum: %s' % (i, round(episode_reward_sum, 2)))\n",
        "                    break\n",
        "            EC = monte_carlo_simulations_new(MC_times,  data, env.currnode)\n",
        "            print('episode%s---reward_EC: %s' % (i, round(EC, 2)))\n",
        "                    \n",
        "            if episode_reward_sum > max_reward_sum:\n",
        "                max_reward_sum = episode_reward_sum\n",
        "                PATH = input_file_path + '/model_' + str(n_users) + '_' + str(K) + '_' + str(round(episode_reward_sum, 2)) + '.txt'\n",
        "                torch.save(dqn.state_dict(), PATH) \n",
        "            "
      ],
      "metadata": {
        "id": "bqZu1Y8idGFF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "input_index = 0\n",
        "n_subarea = 100\n",
        "n_users = 3000 # 5000\n",
        "K = 25 # 50,75,100\n",
        "N_ACTIONS = n_users * n_subarea\n",
        "n_sample = 1 # sample n networks to generalize the model \n",
        "train(n_sample,0)"
      ],
      "metadata": {
        "id": "bbrFscvDRnAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb9ccbd-ba4f-4947-dbdf-ef0be0b6a1b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n user: 3000\n",
            "n seed: 25\n",
            "<<<<<<<<<Episode: 0\n",
            "episode0---reward_sum: 24.8\n",
            "episode0---reward_EC: 25.08\n",
            "<<<<<<<<<Episode: 1\n",
            "episode1---reward_sum: 25.12\n",
            "episode1---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 2\n",
            "episode2---reward_sum: 25.2\n",
            "episode2---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 3\n",
            "episode3---reward_sum: 25.2\n",
            "episode3---reward_EC: 25.08\n",
            "<<<<<<<<<Episode: 4\n",
            "episode4---reward_sum: 25.24\n",
            "episode4---reward_EC: 25.12\n",
            "<<<<<<<<<Episode: 5\n",
            "episode5---reward_sum: 25.16\n",
            "episode5---reward_EC: 25.12\n",
            "<<<<<<<<<Episode: 6\n",
            "episode6---reward_sum: 25.44\n",
            "episode6---reward_EC: 25.08\n",
            "<<<<<<<<<Episode: 7\n",
            "episode7---reward_sum: 25.96\n",
            "episode7---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 8\n",
            "episode8---reward_sum: 24.52\n",
            "episode8---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 9\n",
            "episode9---reward_sum: 24.72\n",
            "episode9---reward_EC: 25.0\n",
            "<<<<<<<<<Episode: 10\n",
            "episode10---reward_sum: 24.76\n",
            "episode10---reward_EC: 25.08\n",
            "<<<<<<<<<Episode: 11\n",
            "episode11---reward_sum: 25.2\n",
            "episode11---reward_EC: 25.2\n",
            "<<<<<<<<<Episode: 12\n",
            "episode12---reward_sum: 24.8\n",
            "episode12---reward_EC: 25.2\n",
            "<<<<<<<<<Episode: 13\n",
            "episode13---reward_sum: 25.52\n",
            "episode13---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 14\n",
            "episode14---reward_sum: 25.08\n",
            "episode14---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 15\n",
            "episode15---reward_sum: 24.36\n",
            "episode15---reward_EC: 25.12\n",
            "<<<<<<<<<Episode: 16\n",
            "episode16---reward_sum: 25.36\n",
            "episode16---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 17\n",
            "episode17---reward_sum: 25.88\n",
            "episode17---reward_EC: 25.08\n",
            "<<<<<<<<<Episode: 18\n",
            "episode18---reward_sum: 25.48\n",
            "episode18---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 19\n",
            "episode19---reward_sum: 25.6\n",
            "episode19---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 20\n",
            "episode20---reward_sum: 24.64\n",
            "episode20---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 21\n",
            "episode21---reward_sum: 25.2\n",
            "episode21---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 22\n",
            "episode22---reward_sum: 24.6\n",
            "episode22---reward_EC: 25.2\n",
            "<<<<<<<<<Episode: 23\n",
            "episode23---reward_sum: 25.72\n",
            "episode23---reward_EC: 25.2\n",
            "<<<<<<<<<Episode: 24\n",
            "episode24---reward_sum: 24.56\n",
            "episode24---reward_EC: 25.08\n",
            "<<<<<<<<<Episode: 25\n",
            "episode25---reward_sum: 25.2\n",
            "episode25---reward_EC: 25.24\n",
            "<<<<<<<<<Episode: 26\n",
            "episode26---reward_sum: 25.56\n",
            "episode26---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 27\n",
            "episode27---reward_sum: 25.24\n",
            "episode27---reward_EC: 25.16\n",
            "<<<<<<<<<Episode: 28\n",
            "episode28---reward_sum: 24.68\n",
            "episode28---reward_EC: 25.04\n",
            "<<<<<<<<<Episode: 29\n",
            "episode29---reward_sum: 25.2\n",
            "episode29---reward_EC: 25.28\n",
            "<<<<<<<<<Episode: 30\n",
            "episode30---reward_sum: 24.92\n",
            "episode30---reward_EC: 25.28\n",
            "<<<<<<<<<Episode: 31\n",
            "episode31---reward_sum: 24.76\n",
            "episode31---reward_EC: 25.12\n",
            "<<<<<<<<<Episode: 32\n",
            "episode32---reward_sum: 24.8\n",
            "episode32---reward_EC: 25.36\n",
            "<<<<<<<<<Episode: 33\n",
            "episode33---reward_sum: 25.68\n",
            "episode33---reward_EC: 25.2\n",
            "<<<<<<<<<Episode: 34\n",
            "episode34---reward_sum: 25.36\n",
            "episode34---reward_EC: 25.28\n",
            "<<<<<<<<<Episode: 35\n",
            "episode35---reward_sum: 25.28\n",
            "episode35---reward_EC: 25.28\n",
            "<<<<<<<<<Episode: 36\n",
            "episode36---reward_sum: 25.8\n",
            "episode36---reward_EC: 25.32\n",
            "<<<<<<<<<Episode: 37\n",
            "episode37---reward_sum: 25.92\n",
            "episode37---reward_EC: 25.12\n",
            "<<<<<<<<<Episode: 38\n",
            "episode38---reward_sum: 26.0\n",
            "episode38---reward_EC: 25.36\n",
            "<<<<<<<<<Episode: 39\n",
            "episode39---reward_sum: 25.52\n",
            "episode39---reward_EC: 25.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "def test(path):\n",
        "  print(\"n user: %d\"%n_users)\n",
        "  print(\"n seed: %d\"%K)\n",
        "\n",
        "  dqn = DQN()   \n",
        "  dqn.load_state_dict(torch.load(path, map_location=device))  \n",
        "  dqn.to(device) \n",
        "  dqn.eval()\n",
        "\n",
        "  n = dqn.gcn_net(data2)\n",
        "  t = dqn.gat_net(data)\n",
        "  k = dqn.agg_net\n",
        "\n",
        "  env = Env(data,data2,K)\n",
        "  s = env.reset()                                  \n",
        "  episode_reward_sum = 0\n",
        "  done = 0    \n",
        "  all_action = set(l)  \n",
        "  curr = set()                                       \n",
        "  A=time.time() \n",
        "  for i in range(K):                                                          \n",
        "    a = dqn.choose_action_ran(s,env.currnode,all_action-env.currnode)\n",
        "    # print(a)                  \n",
        "    s = env.step_ran(a, dqn.gat_net, dqn.gcn_net, dqn.agg_net)   \n",
        "  B=time.time() \n",
        "  EC = monte_carlo_simulations_new(MC_times,  data, env.currnode)\n",
        "  print('---reward_EC: %s' % ( round(EC, 2)))\n",
        "  print('time ',B-A)"
      ],
      "metadata": {
        "id": "J1PaZP_eVf0J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on the test dataset\n",
        "n_subarea = 100\n",
        "n_users = 3000\n",
        "input_file_path = dir+'/New_Gowalla'\n",
        "input_index = 1\n",
        "nodefilename = input_file_path + '/input_node_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "edgefilename = input_file_path + '/input_edge_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "subafilename = input_file_path + '/subarea_pos_subarea_' + str(n_subarea) + '_node_' + str(n_users) + '_' + str(input_index) + '.txt'\n",
        "\n",
        "data = read_graph_pygeo(nodefilename, edgefilename, n_subarea).to(device)\n",
        "data2,l = read_graph_pygeo2(nodefilename, edgefilename, n_subarea, subafilename)\n",
        "data2.to(device)\n",
        "\n",
        "PATH = input_file_path + '/model_' + str(n_users) + '_' + str(25) + '_' + str(25.76) + '.txt'\n",
        "test(PATH)"
      ],
      "metadata": {
        "id": "yuXIgEXQHRDs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "4ddc94b6-0851-489e-deac-0290bc785977"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n user: 3000\n",
            "n seed: 25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-eb1135589274>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_users\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25.76\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-81945fca2a55>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action_ran\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_action\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_ran\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mEC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonte_carlo_simulations_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMC_times\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Env' object has no attribute 'step_ran'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eQfA1hXbyzLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}